{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cf824c-27c3-4d8d-a349-d574d6e93fe7",
   "metadata": {},
   "source": [
    "## Using Laplace Approximation on Cubic Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5610fb2-6fcf-405a-a4b5-d54c70b3e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import make_jaxpr\n",
    "from jax.config import config\n",
    "from jax import value_and_grad\n",
    "from jax import grad, vmap, pmap, jit\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "import optax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import flax\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "import sympy\n",
    "\n",
    "from sympy import Matrix\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a35a5-f532-47e9-8dd0-30f8b8cdab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54224e-fc7c-4dfd-aa7e-baa6b8616213",
   "metadata": {},
   "source": [
    "### Define True Model Function and Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131bafe-14d9-4009-80e4-cdfc602c819b",
   "metadata": {},
   "source": [
    "$ y = 1 + x + 2x^2 + 4x^3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1355f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = 200 #number of known data points\n",
    "\n",
    "t0 = -1.25\n",
    "t1 = 1.25\n",
    "t = jnp.linspace(t0, t1, ndata)\n",
    "\n",
    "def true_fun(t):\n",
    "    return jnp.array([1 + t + 2*t**2 + 4*t**3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b71f4c-f1fc-4c99-9479-1dafb8f8f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev = 3\n",
    "\n",
    "seed = 989\n",
    "np.random.seed(seed)\n",
    "\n",
    "true_y = true_fun(t).squeeze() \n",
    "true_y = true_y + np.random.normal(scale=stdev, size=true_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14265e-51bf-49ba-8e57-cae031e2164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dataset\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(t, true_y.squeeze(), label='Noise Corrupted Data')\n",
    "plt.plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe16747",
   "metadata": {},
   "outputs": [],
   "source": [
    "yscale = jnp.abs(true_y.max()-true_y.min())\n",
    "yscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a8ba6-0cfd-49b5-89e3-d57edb3f6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4596f0f-159e-4841-8b64-d265d6e8763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = true_y[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4152280-e5d1-46b1-b1a7-172eddaff171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ddab59-d863-4a53-95d1-e349c2791c40",
   "metadata": {},
   "source": [
    "### Laplace Approximation Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc1af0-0506-45f5-ac38-3e696fc94fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expanded = np.load('Laplace_cubic_expanded.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c808104-0f2a-47a2-9926-1f7393914d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(expanded[:,3], label='$4x^3$')\n",
    "#plt.axvline(4, 0)\n",
    "plt.xlabel('Parameter Value')\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('Kernel Density Estimate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92fab20-a9bf-4591-b522-e7f4c360713d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "dim = 1\n",
    "\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(t, true_y, label='Noise Corrupted Training Data')\n",
    "plt.plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "plt.plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "    \n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('x')\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf056a-ceb5-4838-ad22-d9f051340ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b40c43b4-ed5d-4a49-b55a-9176c4614445",
   "metadata": {},
   "source": [
    "### MCMC NUTS Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca0523-9ad7-41c2-8dac-987ea118022d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expanded = np.load('nuts_cubic_expanded.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850683e5-31ae-4ee4-a654-695a7a134626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(expanded[:,3], label='$4x^3$')\n",
    "#plt.axvline(4, 0)\n",
    "plt.xlabel('Parameter Value')\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('Kernel Density Estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ff263-c229-4a17-bd84-9bdf3117c4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 1\n",
    "\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(t, true_y, label='Noise Corrupted Training Data')\n",
    "plt.plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "plt.plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "    \n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('x')\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3713d48-cfa6-4943-a831-4b799a0153e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55aa31c4-e795-469d-a8bb-13d6cc72d16c",
   "metadata": {},
   "source": [
    "### Variational Inference Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b56533-a2e5-4e8f-be53-2a55bf8b8974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expanded = np.load('VI_cubic_expanded.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb99a1a-6e26-4255-ac78-ed17df70c9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(expanded[:,3], label='$4x^3$')\n",
    "#plt.axvline(4, 0)\n",
    "plt.xlabel('Parameter Value')\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('Kernel Density Estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c893c8c-565c-4ef5-8b2e-9e03314b6df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "dim = 1\n",
    "\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(t, true_y, label='Noise Corrupted Training Data')\n",
    "plt.plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "plt.plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "    \n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('x')\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b113b2-2a8c-44e1-a8bb-2c7e3ef49889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d88065-8270-4140-acad-13714b347f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77aa8e9c-cdbf-47f7-8bb7-b330c17bb754",
   "metadata": {},
   "source": [
    "### Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fcfc6-949a-4c7c-8152-a69f9622decc",
   "metadata": {
    "tags": []
   },
   "source": [
    "$\\beta = (X^T X)^{-1} X^T y$\n",
    "\n",
    "$ y = x^T \\beta $\n",
    "\n",
    "$I(\\beta) = \\frac{X^T X}{\\sigma^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c1867-b100-45dd-a55b-4ff2ed6631a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = jnp.column_stack((jnp.ones_like(t), t, t**2, t**3))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5449a-6ff1-4f7c-80a5-5395e7fb240a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta = jnp.tensordot(jnp.tensordot(jnp.linalg.inv(jnp.tensordot(X.transpose(), X, (-1,0))), X.transpose(), (-1,0)), true_y, (-1,0))\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a55c8-0fc8-42c7-be27-4ef0ff4239d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cov = jnp.linalg.inv(jnp.tensordot(X.transpose(), X, (-1,0)) / (jnp.var(X @ beta - true_y, ddof=1)))\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b7dfc-d623-48db-b484-b717cf310cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "expanded = np.random.multivariate_normal(beta.squeeze(), cov, 500000)\n",
    "\n",
    "sns.kdeplot(expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(expanded[:,3], label='$4x^3$')\n",
    "#plt.axvline(4, 0)\n",
    "plt.xlabel('Parameter Value')\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('Kernel Density Estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f13a22-becc-44e9-9ebf-b1a9aa0cac0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e5e5b-d640-4357-93e5-74ed23498646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 1\n",
    "\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(t, true_y, label='Noise Corrupted Training Data')\n",
    "plt.plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "plt.plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% confidence interval')\n",
    "    plt.fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "    \n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('x')\n",
    "plt.minorticks_on()\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096ab2e-2075-47a0-b1bd-65fe018a95a1",
   "metadata": {},
   "source": [
    "### Let's combine all of the figures together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943be8d8-009f-4a8c-85c3-13a42ae743f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 15))\n",
    "\n",
    "#Laplace Approximation:----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('Laplace_cubic_expanded.npy')\n",
    "\n",
    "#figure [0,0] kde plot\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,0], label=r'$\\beta_0=1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,1], label=r'$\\beta_1=1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,2], label=r'$\\beta_2=2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,3], label=r'$\\beta_3=4$')\n",
    "axs[0,0].set_ylabel('Kernel Density Estimate')\n",
    "axs[0,0].legend()\n",
    "\n",
    "\n",
    "\n",
    "#figure [0,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[0,1].scatter(t, true_y, label='Training Data')\n",
    "axs[0,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[0,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "axs[0,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "#MCMC NUTS: -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('nuts_cubic_expanded.npy')\n",
    "\n",
    "#figure [1,0] kde plot\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,3], label='$4x^3$')\n",
    "axs[1,0].set_ylabel('Kernel Density Estimate')\n",
    "#axs[1,0].legend()\n",
    "\n",
    "\n",
    "#figure [1,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[1,1].scatter(t, true_y, label='Training Data')\n",
    "axs[1,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[1,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "#axs[1,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MCMC NUTS: -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('VI_cubic_expanded.npy')\n",
    "\n",
    "#figure [2,0] kde plot\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,3], label='$4x^3$')\n",
    "axs[2,0].set_ylabel('Kernel Density Estimate')\n",
    "#axs[1,0].legend()\n",
    "\n",
    "#figure [2,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[2,1].scatter(t, true_y, label='Training Data')\n",
    "axs[2,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[2,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "#axs[2,1].legend()\n",
    "\n",
    "\n",
    "# Bayesian Linear Regression: --------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.random.multivariate_normal(beta.squeeze(), cov, 500000)\n",
    "\n",
    "#figure [3,0] kde plot\n",
    "sns.kdeplot(ax=axs[3,0], data=expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[3,0], data=expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[3,0], data=expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[3,0], data=expanded[:,3], label='$4x^3$')\n",
    "axs[3,0].set_ylabel('Kernel Density Estimate')\n",
    "#axs[2,0].legend()\n",
    "\n",
    "\n",
    "#figure [2,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[3,1].scatter(t, true_y, label='Training Data')\n",
    "axs[3,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[3,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[3,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[3,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[3,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "#axs[3,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[0,0].set_xlim([-2,7])\n",
    "axs[1,0].set_xlim([-2,7])\n",
    "axs[2,0].set_xlim([-2,7])\n",
    "axs[3,0].set_xlim([-2,7])\n",
    "\n",
    "axs[0,1].set_ylabel('y')\n",
    "axs[1,1].set_ylabel('y')\n",
    "axs[2,1].set_ylabel('y')\n",
    "axs[3,1].set_ylabel('y')\n",
    "\n",
    "axs[3,0].set_xlabel('Parameter Value')\n",
    "axs[3,1].set_xlabel('x')\n",
    "\n",
    "axs[0,0].set_ylim([0,1.85])\n",
    "axs[1,0].set_ylim([0,1.85])\n",
    "axs[2,0].set_ylim([0,1.85])\n",
    "axs[3,0].set_ylim([0,1.85])\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.minorticks_on()\n",
    "\n",
    "axs[0,0].set_title('a.) Laplace Approximation', loc='left', pad=10, fontsize=15)\n",
    "axs[1,0].set_title('b.) Markov Chain Monte Carlo', loc='left', pad=10, fontsize=15)\n",
    "axs[2,0].set_title('c.) Variational Inference', loc='left', pad=10, fontsize=15)\n",
    "axs[3,0].set_title('d.) Bayesian Linear Regression', loc='left', pad=10, fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(top=0.25, hspace=0.25) \n",
    "\n",
    "plt.savefig('Cubic_Regression_Comparision.svg')\n",
    "plt.savefig('Cubic_Regression_Comparision.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bb9a3-f267-4b5d-9c21-2ebe013517d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "816577ce-4d75-44a0-a393-d5a88426f304",
   "metadata": {},
   "source": [
    "### Plot showing results for different MCMC sample sizes (500, 1000, and 10000 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded81e3-da71-48bf-a506-de54b4292bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 11.25))\n",
    "\n",
    "#MCMC NUTS with 500 samples:----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('nuts_cubic_expanded_500.npy')\n",
    "\n",
    "#figure [0,0] kde plot\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,0], label=r'$\\beta_0=1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,1], label=r'$\\beta_1=1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,2], label=r'$\\beta_2=2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[0,0], data=expanded[:,3], label=r'$\\beta_3=4$')\n",
    "axs[0,0].set_ylabel('Kernel Density Estimate')\n",
    "axs[0,0].legend()\n",
    "\n",
    "\n",
    "\n",
    "#figure [0,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[0,1].scatter(t, true_y, label='Training Data')\n",
    "axs[0,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[0,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[0,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "axs[0,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "#MCMC NUTS with 1000 samples: -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('nuts_cubic_expanded_1000.npy')\n",
    "\n",
    "#figure [1,0] kde plot\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[1,0], data=expanded[:,3], label='$4x^3$')\n",
    "axs[1,0].set_ylabel('Kernel Density Estimate')\n",
    "#axs[1,0].legend()\n",
    "\n",
    "\n",
    "#figure [1,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[1,1].scatter(t, true_y, label='Training Data')\n",
    "axs[1,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[1,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[1,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "#axs[1,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MCMC NUTS with 10000 samples: -----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "expanded = np.load('nuts_cubic_expanded_10000.npy')\n",
    "\n",
    "#figure [2,0] kde plot\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,0], label='$1$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,1], label='$x$')\n",
    "#plt.axvline(1, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,2], label='$2x^2$')\n",
    "#plt.axvline(2, 0)\n",
    "sns.kdeplot(ax=axs[2,0], data=expanded[:,3], label='$4x^3$')\n",
    "axs[2,0].set_ylabel('Kernel Density Estimate')\n",
    "#axs[1,0].legend()\n",
    "\n",
    "#figure [2,1] regression fit:\n",
    "dim = 1\n",
    "def function2(param_flat, x):\n",
    "    return jnp.dot(jnp.column_stack((jnp.ones_like(t), t, t**2, t**3)), param_flat)\n",
    "\n",
    "params_samples = expanded\n",
    "ys = jax.vmap(function2, (0,None))(params_samples, t)[:,:,None]\n",
    "\n",
    "ys_mean = np.mean(ys, 0)\n",
    "ys_stdev  = np.std(ys, 0)\n",
    "\n",
    "axs[2,1].scatter(t, true_y, label='Training Data')\n",
    "axs[2,1].plot(t, true_fun(t).squeeze() , color='g', label=\"True Model\")\n",
    "axs[2,1].plot(t, ys_mean , color='r', label=\"Mean Model\")\n",
    "for i in range(0, dim):\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]+2.0*ys_stdev[:,i], alpha=0.3,color='royalblue',label='95% CI')\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]+2.0*ys_stdev[:,i], ys_mean[:,i]+3.0*ys_stdev[:,i], alpha=0.3,color='aqua',label='99.7% CI')\n",
    "    axs[2,1].fill_between(t.squeeze(), ys_mean[:,i]-2.0*ys_stdev[:,i], ys_mean[:,i]-3.0*ys_stdev[:,i], alpha=0.3,color='aqua')\n",
    "#axs[2,1].legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[0,0].set_xlim([-2,7])\n",
    "axs[1,0].set_xlim([-2,7])\n",
    "axs[2,0].set_xlim([-2,7])\n",
    "\n",
    "axs[0,1].set_ylabel('y')\n",
    "axs[1,1].set_ylabel('y')\n",
    "axs[2,1].set_ylabel('y')\n",
    "\n",
    "axs[2,0].set_xlabel('Parameter Value')\n",
    "axs[2,1].set_xlabel('x')\n",
    "\n",
    "axs[0,0].set_ylim([0,1.85])\n",
    "axs[1,0].set_ylim([0,1.85])\n",
    "axs[2,0].set_ylim([0,1.85])\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.minorticks_on()\n",
    "\n",
    "axs[0,0].set_title('a.) Markov Chain Monte Carlo (500 samples)', loc='left', pad=10, fontsize=15)\n",
    "axs[1,0].set_title('b.) Markov Chain Monte Carlo (1000 samples)', loc='left', pad=10, fontsize=15)\n",
    "axs[2,0].set_title('c.) Markov Chain Monte Carlo (10000 samples)', loc='left', pad=10, fontsize=15)\n",
    "#axs[3,0].set_title('d.) Bayesian Linear Regression', loc='left', pad=10, fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(top=0.25, hspace=0.25) \n",
    "\n",
    "plt.savefig('Cubic_Regression_mcmc_Comparision.svg')\n",
    "plt.savefig('Cubic_Regression_mcmc_Comparision.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395d778-1e32-456b-96f7-42b642249ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d65122-d655-445d-9b08-fbef1fb45785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45ef66-2241-4f81-a5e3-ac1ac4af997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f4a17-75a7-4879-b0c9-789336384bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
